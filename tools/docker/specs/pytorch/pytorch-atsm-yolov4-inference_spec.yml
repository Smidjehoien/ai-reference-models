releases:
  versioned:
    tag_specs:
    - '{pytorch-ipex-gpu-base-public}{pytorch-atsm-yolov4-inference}'
slice_sets:
  pytorch-atsm-yolov4-inference:
  - add_to_name: -pytorch-atsm-yolov4-inference
    dockerfile_exclusive_name: -yolov4-inference
    args:
    - PACKAGE_NAME=pytorch-atsm-yolov4-inference
    dockerfile_subdirectory: gpu_model_containers
    documentation:
      - docs:
        - name: Title
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/title.md
        - name: Description
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/description.md
        - name : GPU Setup
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/gpu_setup.md
        - name: Datasets
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/datasets.md
        - name: Quick Start Scripts
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/quickstart.md
        - name: Baremetal
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/baremetal.md
        - name: License
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/license.md
        name: README.md
        text_replace:
          <device>: Intel® Data Center GPU Flex Series
          <mode>: inference
          <model name>: YOLOv4
          <model-precision-mode>: pytorch-atsm-yolov4-inference
          <package dir>: pytorch-atsm-yolov4-inference
          <use case>: object_detection
        uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu
      - docs:
        - name: Title
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/title.md
        - name: Description
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/description.md
        - name: Package
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/package.md
        - name: Datasets
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/datasets.md
        - name: Quick Start Scripts
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/quickstart.md
        - name: Docker
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/docker.md
        - name: License
          uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu/.docs/license.md
        name: wrapper_README.md
        text_replace:
          <device>: Intel® Data Center GPU Flex Series
          <mode>: inference
          <model name>: YOLOv4
          <model-precision-mode>: pytorch-atsm-yolov4-inference
          <package dir>: pytorch-atsm-yolov4-inference
          <package name>: pytorch-atsm-yolov4-inference.tar.gz
          <use case>: object_detection
        uri: models/quickstart/object_detection/pytorch/yolov4/inference/gpu
    downloads: []
    files:
    - source: quickstart/object_detection/pytorch/yolov4/inference/gpu/README.md
      destination: README.md
    - destination: models/object_detection/pytorch/yolov4/inference/gpu
      source: models/object_detection/pytorch/yolov4/inference/gpu
    - destination: quickstart/inference_with_dummy_data.sh
      source: quickstart/object_detection/pytorch/yolov4/inference/gpu/inference_with_dummy_data.sh
    - destination: quickstart/requirements.txt
      source: quickstart/object_detection/pytorch/yolov4/inference/gpu/requirements.txt
    - destination: quickstart/setup.sh
      source: quickstart/object_detection/pytorch/yolov4/inference/gpu/setup.sh
    wrapper_package_files:
     - source: quickstart/object_detection/pytorch/yolov4/inference/gpu/README.md
       destination: README.md
     - source: quickstart/object_detection/pytorch/yolov4/inference/gpu/build.sh
       destination: build.sh
     - source: quickstart/object_detection/pytorch/yolov4/inference/gpu/run.sh
       destination: run.sh
     - source: dockerfiles/gpu_model_containers/pytorch-atsm-yolov4-inference.Dockerfile
       destination: pytorch-atsm-yolov4-inference.Dockerfile
     - source: output/pytorch-atsm-yolov4-inference.tar.gz
       destination: model_packages/pytorch-atsm-yolov4-inference.tar.gz
     - source: ""
       destination: info.txt
     - source: third_party
       destination: licenses/third_party
     - source: LICENSE
       destination: licenses/LICENSE
    partials:
    - numactl
    - python-build
    - opencv
    - object_detection/pip_installs
    - model_package
    - entrypoint
