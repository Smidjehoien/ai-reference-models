releases:
  versioned:
    tag_specs:
    - '{spr-transformer-mlperf-inference}'
slice_sets:
  spr-transformer-mlperf-inference:
    - add_to_name: tf-spr-transformer-mlperf-inference
      dockerfile_subdirectory: tensorflow-spr
      args:
        - PACKAGE_NAME=tf-spr-transformer-mlperf-inference
        - TENSORFLOW_IMAGE=model-zoo
        - TENSORFLOW_TAG=tensorflow-spr
      partials:
        - tensorflow/tensorflow-base
        - common
        - model_package
        - entrypoint
      files:
        - destination: benchmarks/common
          source: benchmarks/common
        - destination: benchmarks/object_detection/__init__.py
          source: benchmarks/object_detection/__init__.py
        - destination: benchmarks/language_translation/tensorflow/__init__.py
          source: benchmarks/language_translation/tensorflow/__init__.py
        - destination: benchmarks/language_translation/tensorflow/transformer_mlperf/README.md
          source: benchmarks/language_translation/tensorflow/transformer_mlperf/README.md
        - destination: benchmarks/language_translation/tensorflow/transformer_mlperf/inference
          source: benchmarks/language_translation/tensorflow/transformer_mlperf/inference
        - destination: benchmarks/launch_benchmark.py
          source: benchmarks/launch_benchmark.py
        - source: quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/inference_realtime.sh
          destination: quickstart/inference_realtime.sh
        - source: quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/inference_throughput.sh
          destination: quickstart/inference_throughput.sh
        - source: quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/accuracy.sh
          destination: quickstart/accuracy.sh
        - destination: models/common
          source: models/common
        - destination: models/language_translation/tensorflow/transformer_mlperf/inference
          source: models/language_translation/tensorflow/transformer_mlperf/inference
        - destination: quickstart/common
          source: quickstart/common
      downloads:
        - source: https://ubit-artifactory-or.intel.com/artifactory/cicd-or-local/model-zoo/spr/2022/tensorflow/ww18/tf_dataset/pre-trained-models/transformer_mlperf/bfloat16/transformer_mlperf_bf16.pb
          destination: pretrained_model/transformer_mlperf_bf16.pb
        - source: https://ubit-artifactory-or.intel.com/artifactory/cicd-or-local/model-zoo/spr/2022/tensorflow/ww18/tf_dataset/pre-trained-models/transformer_mlperf/fp32/transformer_mlperf_fp32.pb
          destination: pretrained_model/transformer_mlperf_fp32.pb
        - source: https://ubit-artifactory-or.intel.com/artifactory/cicd-or-local/model-zoo/spr/2022/tensorflow/ww18/tf_dataset/pre-trained-models/transformer_mlperf/int8/transformer_mlperf_int8.pb
          destination: pretrained_model/transformer_mlperf_int8.pb
      wrapper_package_files:
        - source: output/tf-spr-transformer-mlperf-inference.tar.gz
          destination: model_packages/tf-spr-transformer-mlperf-inference.tar.gz
        - source: quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/build.sh
          destination: build.sh
        - source: quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/run.sh
          destination: run.sh
        - source: dockerfiles/tensorflow-spr/tf-spr-transformer-mlperf-inference.Dockerfile
          destination: tf-spr-transformer-mlperf-inference.Dockerfile
        - source: LICENSE
          destination: licenses/LICENSE
        - source: third_party
          destination: licenses/third_party
        - source: quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/README_SPR.md
          destination: README.md
      documentation:
        - docs:
          - name: Title
            uri: models/quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/.docs/title.md
          - name: Description
            uri: models/quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/.docs/description.md
          - name: Model Package
            uri: models/quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/.docs/wrapper_package.md
          - name: Quickstart
            uri: models/quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/.docs/quickstart.md
          - name: Datasets
            uri: models/quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/.docs/datasets.md
          - name: Container build
            uri: models/quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/.docs/container_build.md
          - name: Docker
            uri: models/quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/.docs/docker_spr.md
          - name: License
            uri: models/quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu/.docs/license.md
          name: README_SPR.md
          text_replace:
            <model name>: Transformer Language
            <mode>: inference
            <package name>: tf-spr-transformer-mlperf-inference.tar.gz
            <package dir>: tf-spr-transformer-mlperf-inference
            <docker image>: model-zoo:tf-spr-transformer-mlperf-inference
          uri: models/quickstart/language_translation/tensorflow/transformer_mlperf/inference/cpu
