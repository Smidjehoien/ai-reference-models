{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Intel® AI Reference Models Jupyter Notebook\n",
    "\n",
    "This Jupyter notebook helps you choose and run a comparison between two models from the Intel® AI Reference Models repo using Intel® Optimizations for TensorFlow*, Intel® extension for TensorFlow, Intel® Optimizations for PyTorch and Intel® extension for PyTorch. When you run the notebook, it installs required package dependencies, displays information about your platform, lets you choose the two models to compare, runs those models, and finally displays a performance comparison chart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Create a Digraph object\n",
    "general_graph = Digraph()\n",
    "\n",
    "# Define the nodes\n",
    "general_graph.node('G', 'General Specification')\n",
    "\n",
    "general_graph.node('F', 'Framework')\n",
    "general_graph.node('PyT', 'PyTorch')\n",
    "general_graph.node('TF', 'TensorFlow')\n",
    "\n",
    "general_graph.node('HW', 'Hardware')\n",
    "general_graph.node('CPU', 'CPU')\n",
    "general_graph.node('GPU', 'GPU')\n",
    "\n",
    "general_graph.node('Flex', 'Flex')\n",
    "general_graph.node('Max', 'Max')\n",
    "general_graph.node('Arc', 'Arc')\n",
    "\n",
    "\n",
    "# Define the edges\n",
    "general_graph.edges([('G','F'), ('F','PyT'), ('F','TF'), ('PyT', 'HW'), ('TF', 'HW'), ('HW', 'CPU'), ('HW', 'GPU'), ('GPU', 'Flex'), ('GPU', 'Max'), ('GPU', 'Arc')])\n",
    "# Save the graph to a file\n",
    "general_graph.render('simple_flow_chart', format='png', cleanup=True)\n",
    "\n",
    "# Display the image in the notebook\n",
    "display(Image(filename='simple_flow_chart.png'))\n",
    "\n",
    "model_graph = Digraph()\n",
    "model_graph.node('M','Model Specification')\n",
    "model_graph.node('TM','Test_Mode')\n",
    "model_graph.node('Mo','Mode')\n",
    "model_graph.node('P','Precision')\n",
    "model_graph.node('S','Script')\n",
    "model_graph.node('AS','Additional Setup')\n",
    "model_graph.node('PL','Pretrained/Log Directory')\n",
    "model_graph.node('R','Run')\n",
    "\n",
    "model_graph.edges([('M','TM'), ('M','Mo'),('M','P'),('M','S'),('TM','AS'),('Mo','AS'),('P','AS'),('S','AS'),('AS','PL'),('PL','R')])\n",
    "model_graph.render('simple_flow_chart_1', format='png', cleanup=True)\n",
    "display(Image(filename='simple_flow_chart_1.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_1'></a>\n",
    "# Step 1: Display Platform Information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required dependencies for the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install matplotlib ipykernel psutil pandas cxxfilt gitpython wheel pyyaml ipython\n",
    "!pip install gcg\n",
    "!python3 -m pip install gitpython\n",
    "!pip install prettytable\n",
    "!pip install --upgrade matplotlib\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a framework from the dropdown option below the next cell and install the required framework packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from profiling.profile_utils import GeneralConfigFile, AIReferenceConfigFile\n",
    "from prettytable import PrettyTable\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ['no_proxy'] = \"\"\n",
    "os.environ['NO_PROXY'] = \"\"\n",
    "general_config_1 = GeneralConfigFile(ai_root=os.getcwd()+'/..')\n",
    "general_config_1.toggle_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "if (general_config_1.hardware_dropdown.value and general_config_1.framework_dropdown.value and (general_config_1.hardware_dropdown.value == 'CPU' or (general_config_1.hardware_dropdown.value == 'GPU' and general_config_1.gpu_series_dropdown.value))):\n",
    "    current_dir = current_directory = os.getcwd()\n",
    "    selected_hardware = general_config_1.hardware_dropdown.value\n",
    "    selected_framework = general_config_1.framework_dropdown.value\n",
    "\n",
    "    if selected_framework == 'PyTorch':\n",
    "        if selected_hardware == 'CPU':\n",
    "            !python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "            !python -m pip install intel-extension-for-pytorch\n",
    "            !python -m pip install oneccl_bind_pt --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/cpu/us/\n",
    "\n",
    "            print(\"PyTorch CPU packages installed.\")\n",
    "\n",
    "            !./profiling/pytorch_cpu_setup.sh\n",
    "\n",
    "            !pip install packaging intel-openmp\n",
    "\n",
    "            os.environ[\"LD_PRELOAD\"] = f\"{current_dir}/jemalloc/lib/libjemalloc.so:{current_dir}/tcmalloc/lib/libtcmalloc.so:{general_config_1.root}/new_env/lib/libiomp5.so\"\n",
    "            os.environ[\"MALLOC_CONF\"] = \"oversize_threshold:1,background_thread:true,metadata_thp:auto,dirty_decay_ms:9000000000,muzzy_decay_ms:9000000000\"\n",
    "            os.environ[\"DNNL_MAX_CPU_ISA\"] = \"AVX512_CORE_AMX\"\n",
    "            os.environ['yaml_file'] = 'profiling/ai_reference_models_pytorch_cpu.yaml'\n",
    "\n",
    "            print(\"Finish building PyTorch for CPU\")\n",
    "\n",
    "        elif selected_hardware == 'GPU':\n",
    "            install_oneapi = general_config_1.intel_oneapi_dropdown.value\n",
    "            gpu_series = general_config_1.gpu_series_dropdown.value\n",
    "\n",
    "            if (install_oneapi):\n",
    "                print(\"Intel® oneAPI Base Toolkit is installed\")\n",
    "                print(\"Installing PyTorch for GPU...\")\n",
    "                !pip install torch==2.1.0a0 torchvision==0.16.a0 torchaudio==2.1.0.a0 intel-extension-for-pytorch==2.1.10+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/\n",
    "                print(\"IPEX GPU packages installed.\")\n",
    "\n",
    "                if gpu_series == 'Flex':\n",
    "                    os.environ['yaml_file'] = f\"{current_dir}/profiling/ai_reference_models_pytorch_flex_gpu.yaml\"\n",
    "                elif gpu_series == 'Max':\n",
    "                    os.environ['yaml_file'] = f\"{current_dir}/profiling/ai_reference_models_pytorch_max_gpu.yaml\"\n",
    "                elif gpu_series == 'Arc':\n",
    "                    os.environ['yaml_file'] = f\"{current_dir}/profiling/ai_reference_models_pytorch_arc_gpu.yaml\"\n",
    "\n",
    "                oneapi_path = general_config_1.oneapi_path_input.value.strip()\n",
    "                print(\"Finish building IPEX for GPU\")\n",
    "                os.environ['oneAPI_PATH'] = oneapi_path\n",
    "                oneAPI_PATH = os.environ.get('oneAPI_PATH', '')\n",
    "                script_content = f\"\"\"\n",
    "                source /{oneAPI_PATH}/compiler/latest/env/vars.sh\n",
    "                source /{oneAPI_PATH}/mkl/latest/env/vars.sh\n",
    "                source /{oneAPI_PATH}/tbb/latest/env/vars.sh\n",
    "                source /{oneAPI_PATH}/mpi/latest/env/vars.sh\n",
    "                source /{oneAPI_PATH}/ccl/latest/env/vars.sh\n",
    "                \"\"\"\n",
    "                subprocess.run([\"/bin/bash\", \"-c\", script_content], check=True)\n",
    "                print(\"One API sourcing done.\")\n",
    "                print(\"PyTorch GPU packages installed.\")\n",
    "\n",
    "    elif selected_framework == 'TensorFlow':\n",
    "        if selected_hardware == 'CPU':\n",
    "            !pip cache purge\n",
    "            !pip install --upgrade tf-nightly-cpu\n",
    "            !pip install --upgrade tf-keras-nightly\n",
    "            !pip install --upgrade tf-estimator-nightly\n",
    "            print(\"TensorFlow packages installed.\")\n",
    "            os.environ['yaml_file'] = 'profiling/ai_reference_models_tensorflow_cpu.yaml'\n",
    "            print(\"Finish building TF for CPU\")\n",
    "\n",
    "        elif selected_hardware == 'GPU':\n",
    "            gpu_series = general_config_1.gpu_series_dropdown.value\n",
    "            print(\"Installing TensorFlow and ITEX for GPU...\")\n",
    "            !pip install tensorflow==2.15.0\n",
    "\n",
    "            !pip install --upgrade intel-extension-for-tensorflow[xpu]\n",
    "\n",
    "            if gpu_series == 'Flex':\n",
    "                os.environ['yaml_file'] = f\"{current_dir}/profiling/ai_reference_models_tensorflow_flex_gpu.yaml\"\n",
    "            elif gpu_series == 'Max':\n",
    "                os.environ['yaml_file'] = f\"{current_dir}/profiling/ai_reference_models_tensorflow_max_gpu.yaml\"\n",
    "            elif gpu_series == 'Arc':\n",
    "                os.environ['yaml_file'] = f\"{current_dir}/profiling/ai_reference_models_tensorflow_arc_gpu.yaml\"\n",
    "            print(\"TensorFlow GPU packages installed.\")\n",
    "\n",
    "else:\n",
    "    raise Exception(\"Please rerun the selections to ensure correct installations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Set the path for the AI reference models, assumed to be the current working directory, and the path for the utility functions directory inside the cloned Intel® AI Reference Models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# If default path does not work, change AIReferenceRoot path according to your environment\n",
    "os.environ['NotebookRoot'] = os.getcwd()\n",
    "os.environ['AIReferenceRoot'] = os.environ['NotebookRoot'] + os.sep\n",
    "os.environ['ProfileUtilsRoot'] = os.environ['AIReferenceRoot'] + os.sep + \"notebooks/profiling/\"\n",
    "print(\"Path for the notebook root is: \", os.environ['NotebookRoot'])\n",
    "print(\"Path for the AI Reference Models root is: \", os.environ['AIReferenceRoot'])\n",
    "print(\"Path for utility functions directory is: \", os.environ['ProfileUtilsRoot'])\n",
    "\n",
    "# Check for mandatory python scripts after AIReferenceRoot and ProfileUtilsRoot are assigned\n",
    "import os\n",
    "current_path = os.getcwd()\n",
    "benchmark_path = os.environ['AIReferenceRoot'] + os.sep + \"benchmarks/launch_benchmark.py\"\n",
    "if os.path.exists(benchmark_path) == True:\n",
    "    print(benchmark_path)\n",
    "else:\n",
    "    print(benchmark_path)\n",
    "    print(\"ERROR! Can't find benchmark/launch_benchmark.py script!\")\n",
    "\n",
    "profile_utils_path = os.environ['ProfileUtilsRoot'] + \"profile_utils.py\"\n",
    "if os.path.exists(profile_utils_path) == True:\n",
    "    print(profile_utils_path)\n",
    "else:\n",
    "    print(\"ERROR! Can't find profile_utils.py script!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run the first model\n",
    "\n",
    "This notebook helps you compare the performance of two models listed in the supported models. Select the first model to run and compare.  (If the environment variable MODEL_1_INDEX is set, we'll use that instead of prompting for input.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Display all the supported models and select first  model to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "config_1 = AIReferenceConfigFile(os.environ['yaml_file'], os.getcwd() + '/..')\n",
    "notebook_root = config_1.notebook_root\n",
    "%cd $notebook_root\n",
    "selected_model = config_1.model_selection()\n",
    "print(selected_model)\n",
    "selected_model = config_1.device_specific(selected_model, general_config_1.hardware_dropdown.value, os.environ['yaml_file'], selected_framework)\n",
    "os.environ['PRECISION'] = config_1.precision\n",
    "if selected_framework == 'TensorFlow' and selected_hardware == 'CPU':\n",
    "    selected_script = config_1.script\n",
    "else:\n",
    "    os.environ['TEST_MODE'] = config_1.test_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell checks for additional environment variables that needs to be specified per model specification.\n",
    "\n",
    "Then checks for additional files, libraries, and configurations that needs to be installed per model specification. Commands are installed in a chronological dependency order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "ai_reference_root = config_1.ai_root\n",
    "%cd $ai_reference_root\n",
    "\n",
    "for export in selected_model['exports']:\n",
    "    env_name = export.split(' ')[0]\n",
    "    env_value = export.split(' ')[1]\n",
    "    if env_value == '-i':\n",
    "        env_value = input(f'Please provide the path for the following environment variable {env_name}: ', )\n",
    "    os.environ[env_name] = os.path.expandvars(env_value)\n",
    "\n",
    "    print(\"Assigned environment variable \", env_name, \" : \", os.environ[env_name])\n",
    "\n",
    "for cmd in selected_model['additional-commands']:\n",
    "    if 'os.environ' in cmd: exec(cmd)\n",
    "    else : subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Retrieve the AI reference root from environment variables\n",
    "ai_reference_root = os.environ.get('AIReferenceRoot')\n",
    "if not ai_reference_root:\n",
    "    raise ValueError(\"Environment variable 'AIReferenceRoot' is not set.\")\n",
    "\n",
    "# Change to the specified directory\n",
    "os.chdir(ai_reference_root)\n",
    "\n",
    "# Process exports from the selected model\n",
    "exports = selected_model.get('exports', [])\n",
    "for export in exports:\n",
    "    try:\n",
    "        # Split the export string into name and value\n",
    "        env_parts = export.split(' ', 1)\n",
    "        if len(env_parts) != 2:\n",
    "            raise ValueError(f\"Invalid export format: {export}\")\n",
    "\n",
    "        env_name, env_value = env_parts\n",
    "        if env_value == '-i':\n",
    "            # Prompt for user input if value is '-i'\n",
    "            env_value = input(f\"Please provide the path for the environment variable '{env_name}': \")\n",
    "\n",
    "        # Expand and set the environment variable\n",
    "        os.environ[env_name] = os.path.expandvars(env_value)\n",
    "        print(f\"Assigned environment variable {env_name}: {os.environ[env_name]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing export '{export}': {e}\")\n",
    "\n",
    "# Process additional commands from the selected model\n",
    "additional_commands = selected_model.get('additional-commands', [])\n",
    "for cmd in additional_commands:\n",
    "    try:\n",
    "        if 'os.environ' in cmd:\n",
    "            # Execute Python commands directly\n",
    "            exec(cmd)\n",
    "        else:\n",
    "            # Execute shell commands\n",
    "            subprocess.call(cmd, shell=True)\n",
    "        print(f\"Executed command: {cmd}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing command '{cmd}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Get the required dataset for the selected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell checks the dataset path. If the data-location is already specified, then the notebook will use the dataset path mentioned in ai_reference_models.ini file. If the data-location is not specified in the ai_reference_models.ini, the data downloading option instructions are shown. You must manually download the dataset using these instructions before you can proceed to the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path for dataset directory for the first model:\n",
    "\n",
    "DATASET_DIR': the path where the dataset exists and is downloaded.\n",
    "\n",
    "**ACTION : You need to input the path where the dataset for the first model exists or where you have downloaded it in your system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = input('Input the path where the dataset exists for the first model:')\n",
    "\n",
    "os.environ['DATASET_DIR'] = dataset_path\n",
    "\n",
    "print(\"Data location path:\", os.environ['DATASET_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3: Prepare pre-trained model for the selected model\n",
    "\n",
    "This step checks if the pre-trained model for the selected model exists in the pre-trained directory path. If the pre-trained directory does not exist, then it downloads the pre-trained model for the selected precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "wget_value = config_1.wget\n",
    "\n",
    "pretrain_model_path = config_1.download_pretrained_model(wget=wget_value, current_path=config_1.notebook_root)\n",
    "pretrain_model_path = config_1.uncompress_file(pretrain_model_path, current_path=config_1.notebook_root)\n",
    "if pretrain_model_path:\n",
    "    print('Downloaded the model in:', pretrain_model_path)\n",
    "else:\n",
    "    print('Failed to download the pretrained model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the environment variable for pre-trained model for the first model:\n",
    "\n",
    "'PRETRAINED_MODEL': the path where is the pretrained_model exists and is downloaded.\n",
    "\n",
    "NOTE: You can change the value of 'PRETRAINED_MODEL' by changing its assignment in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"PRETRAINED_MODEL\"]=pretrain_model_path\n",
    "print(\"Pretrain_model_path:\", os.environ[\"PRETRAINED_MODEL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.4: Set the log directory or output directory\n",
    "\n",
    "'OUTPUT_DIR': the output directory path where model output logs are collected.\n",
    "\n",
    "The default directory name for the output logs is \\\"logs\\\" in the current working directory. You can change this directory name by replacing the value assigned to log_directory in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Set the log directory/output directory to store the logs\n",
    "log_directory= config_1.notebook_root + os.sep + \"logs\"\n",
    "print(log_directory)\n",
    "\n",
    "os.environ['OUTPUT_DIR']=log_directory\n",
    "print(\"Output directory path is:\", os.environ['OUTPUT_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.5:  Run the first Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**if BATCH_SIZE is specified per model specification, set it for optimal batch size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "if selected_model['set-batch-size']['cores']:\n",
    "    import subprocess\n",
    "\n",
    "    # Run the shell command to get the number of cores\n",
    "    output = subprocess.check_output(\"lscpu | grep 'Core(s) per socket' | awk '{print $4}'\", shell=True)\n",
    "\n",
    "    # Decode the byte string output into a regular Python string\n",
    "    cores = int(output.decode(\"utf-8\").strip())\n",
    "\n",
    "    cores = eval(selected_section['set-batch-size']['expr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPTIONAL: You can change the batch size from the model's default. For online_inference,  set batch_size value to be 1.** \n",
    "\n",
    "**Run the next cell if you want to change the batch-size, other skip running the next cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "batch_size= input('Set the value for batch size that you want to run: ')\n",
    "os.environ[\"BATCH_SIZE\"]=batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the first model using the quickstart script configured in the ai_reference_models.ini file, and save output logs to the selected log directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Ensure the AI Reference Root is set and navigate to it\n",
    "ai_reference_root = os.environ.get('AIReferenceRoot', None)\n",
    "if not ai_reference_root or not os.path.isdir(ai_reference_root):\n",
    "    raise FileNotFoundError(\"AIReferenceRoot environment variable is not set or points to an invalid directory.\")\n",
    "os.chdir(ai_reference_root)\n",
    "\n",
    "# Get the YAML file name from environment variables\n",
    "yaml_file = os.environ.get('yaml_file', None)\n",
    "if not yaml_file:\n",
    "    raise ValueError(\"yaml_file environment variable is not set.\")\n",
    "\n",
    "# Debugging: Print the YAML file value\n",
    "print(f\"yaml_file: {yaml_file}\")\n",
    "\n",
    "# Construct the config path\n",
    "configpath = os.path.join(ai_reference_root, \"notebooks\", yaml_file)\n",
    "\n",
    "# Debugging: Print the full path to the YAML file\n",
    "print(f\"Constructed configpath: {configpath}\")\n",
    "\n",
    "# Check if the configuration file exists\n",
    "if not os.path.isfile(configpath):\n",
    "    raise FileNotFoundError(f\"Configuration file not found: {configpath}\")\n",
    "\n",
    "config_1 = AIReferenceConfigFile(os.environ['yaml_file'], os.getcwd() + '/..')\n",
    "# Build log name\n",
    "parts = config_1.model_name.split()\n",
    "log_name = '-'.join(parts) + \".log\"\n",
    "\n",
    "# Check for hardware and framework combination\n",
    "if general_config_1.hardware_dropdown.value == 'CPU' and general_config_1.framework_dropdown.value == 'TensorFlow':\n",
    "    # Build command for TensorFlow CPU workload\n",
    "    run_workload = f\"models_v2/{config_1.framework}/{config_1.model_name}/{config_1.mode}/cpu/{config_1.script}\"\n",
    "    log_name = f\"{config_1.model_name}-{config_1.framework}-cpu.log\"\n",
    "    cmd = f\"./{run_workload} precision={config_1.precision} | tee {log_directory}/{log_name}\"\n",
    "\n",
    "    print(\"Running:\", cmd)\n",
    "    subprocess.call(cmd, shell=True)\n",
    "\n",
    "else:\n",
    "    # Construct the directory path\n",
    "    dir_path = os.path.normpath(f\"models_v2/{config_1.framework}/{config_1.model_name}/{config_1.mode}/{config_1.device}\")\n",
    "\n",
    "    # Debugging: Print the final directory path\n",
    "    print(f\"Final dir_path: {dir_path}\")\n",
    "\n",
    "    if not os.path.isdir(dir_path):\n",
    "        raise FileNotFoundError(f\"Directory not found: {dir_path}\")\n",
    "\n",
    "    # Navigate to the directory\n",
    "    os.chdir(dir_path)\n",
    "    print(f\"Running in directory: {dir_path}\")\n",
    "\n",
    "    # Run setup and model scripts\n",
    "    subprocess.call(\"bash ./setup.sh\", shell=True)\n",
    "    subprocess.call(\"bash ./run_model.sh\", shell=True)\n",
    "\n",
    "    # Navigate back to the previous directory\n",
    "    os.chdir(ai_reference_root)\n",
    "\n",
    "# Navigate back to the original directory (AI Reference Root)\n",
    "os.chdir(ai_reference_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.6 Get the throughput or accuracy of the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Throughput of first workload:\n",
    "# Split the model_name into individual parts\n",
    "\n",
    "import re, statistics\n",
    "try:\n",
    "    with open(f'{log_directory}/{log_name}', 'r') as file:\n",
    "        print(\"DEBUGGING: FILE DIRECTORY:\", f'{log_directory}/{log_name}')\n",
    "        file_content = file.read()\n",
    "        throughput_matches = re.findall(r'Throughput[^:]*:\\s*(\\d+\\.\\d+)\\s+fps', file_content)\n",
    "        accuracy_matches = re.findall(r'Accuracy[^:]*:\\s*(\\d+\\.\\d+)', file_content)\n",
    "        if throughput_matches:\n",
    "            throughput_matches = [float(x) for x in throughput_matches]\n",
    "            throughput_value = float(statistics.mean(throughput_matches))\n",
    "            print(f'Throughput: {throughput_value} fps')\n",
    "        else:\n",
    "            print('Throughput not found in the file.')\n",
    "        if accuracy_matches:\n",
    "            accuracy_matches = [float(x) for x in accuracy_matches]\n",
    "            accuracy_value = float(statistics.mean(accuracy_matches))\n",
    "            print(f'Accuracy: {accuracy_value}')\n",
    "        else:\n",
    "            print('Accuracy not found in the file')\n",
    "\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print('File not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Select and run the second model\n",
    "\n",
    "Let's now run a second model and compare its performance with the first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1 Select another model for comparision\n",
    "\n",
    "After the list of models is displayed, select one by entering the model index number. (If the environment variable MODEL_2_INDEX is set, we'll use that instead of prompting for input.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%cd $notebook_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "general_config_2 = GeneralConfigFile(ai_root=os.getcwd()+'/..')\n",
    "general_config_2.toggle_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "if (general_config_2.hardware_dropdown.value and general_config_2.framework_dropdown.value and (general_config_2.hardware_dropdown.value == 'CPU' or (general_config_2.hardware_dropdown.value == 'GPU' and general_config_2.gpu_series_dropdown.value))):\n",
    "    current_dir = current_directory = os.getcwd()\n",
    "    selected_hardware = general_config_2.hardware_dropdown.value\n",
    "    selected_framework = general_config_2.framework_dropdown.value\n",
    "\n",
    "    if selected_framework == 'PyTorch':\n",
    "        if selected_hardware == 'CPU':\n",
    "            !python -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "            !python -m pip install intel-extension-for-pytorch\n",
    "            !python -m pip install oneccl_bind_pt --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/cpu/us/\n",
    "\n",
    "            print(\"PyTorch CPU packages installed.\")\n",
    "\n",
    "            !./profiling/pytorch_cpu_setup.sh\n",
    "\n",
    "            !pip install packaging intel-openmp\n",
    "\n",
    "            os.environ[\"LD_PRELOAD\"] = f\"{current_dir}/jemalloc/lib/libjemalloc.so:{current_dir}/tcmalloc/lib/libtcmalloc.so:{general_config_1.root}/new_env/lib/libiomp5.so\"\n",
    "            os.environ[\"MALLOC_CONF\"] = \"oversize_threshold:1,background_thread:true,metadata_thp:auto,dirty_decay_ms:9000000000,muzzy_decay_ms:9000000000\"\n",
    "            os.environ[\"DNNL_MAX_CPU_ISA\"] = \"AVX512_CORE_AMX\"\n",
    "            os.environ['yaml_file'] = 'profiling/ai_reference_models_pytorch_cpu.yaml'\n",
    "\n",
    "            print(\"Finish building PyTorch for CPU\")\n",
    "\n",
    "        elif selected_hardware == 'GPU':\n",
    "            install_oneapi = general_config_2.intel_oneapi_dropdown.value\n",
    "            gpu_series = general_config_2.gpu_series_dropdown.value\n",
    "\n",
    "            if (install_oneapi):\n",
    "                print(\"Intel® oneAPI Base Toolkit is installed\")\n",
    "                print(\"Installing PyTorch for GPU...\")\n",
    "                !pip install torch==2.1.0a0 torchvision==0.16.a0 torchaudio==2.1.0.a0 intel-extension-for-pytorch==2.1.10+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/\n",
    "                print(\"IPEX GPU packages installed.\")\n",
    "\n",
    "                if gpu_series == 'Flex':\n",
    "                    os.environ['yaml_file'] = f\"{current_dir}/profiling/ai_reference_models_pytorch_flex_gpu.yaml\"\n",
    "                elif gpu_series == 'Max':\n",
    "                    os.environ['yaml_file'] = f\"{current_dir}/profiling/ai_reference_models_pytorch_max_gpu.yaml\"\n",
    "                elif gpu_series == 'Arc':\n",
    "                    os.environ['yaml_file'] = f\"{current_dir}/profiling/ai_reference_models_pytorch_arc_gpu.yaml\"\n",
    "\n",
    "                oneapi_path = general_config_2.oneapi_path_input.value.strip()\n",
    "                print(\"Finish building IPEX for GPU\")\n",
    "                os.environ['oneAPI_PATH'] = oneapi_path\n",
    "                oneAPI_PATH = os.environ.get('oneAPI_PATH', '')\n",
    "                script_content = f\"\"\"\n",
    "                source /{oneAPI_PATH}/compiler/latest/env/vars.sh\n",
    "                source /{oneAPI_PATH}/mkl/latest/env/vars.sh\n",
    "                source /{oneAPI_PATH}/tbb/latest/env/vars.sh\n",
    "                source /{oneAPI_PATH}/mpi/latest/env/vars.sh\n",
    "                source /{oneAPI_PATH}/ccl/latest/env/vars.sh\n",
    "                \"\"\"\n",
    "                subprocess.run([\"/bin/bash\", \"-c\", script_content], check=True)\n",
    "                print(\"One API sourcing done.\")\n",
    "                print(\"PyTorch GPU packages installed.\")\n",
    "\n",
    "    elif selected_framework == 'TensorFlow':\n",
    "        if selected_hardware == 'CPU':\n",
    "            !pip cache purge\n",
    "            !pip install --upgrade tf-nightly-cpu\n",
    "            !pip install --upgrade tf-keras-nightly\n",
    "            !pip install --upgrade tf-estimator-nightly\n",
    "            print(\"TensorFlow packages installed.\")\n",
    "            os.environ['yaml_file'] = 'profiling/ai_reference_models_tensorflow_cpu.yaml'\n",
    "            print(\"Finish building TF for CPU\")\n",
    "\n",
    "        elif selected_hardware == 'GPU':\n",
    "            gpu_series = general_config_2.gpu_series_dropdown.value\n",
    "            print(\"Installing TensorFlow and ITEX for GPU...\")\n",
    "            !pip install tensorflow==2.15.0\n",
    "\n",
    "            !pip install --upgrade intel-extension-for-tensorflow[xpu]\n",
    "\n",
    "            if gpu_series == 'Flex':\n",
    "                os.environ['yaml_file'] = f\"{current_dir}/profiling/ai_reference_models_tensorflow_flex_gpu.yaml\"\n",
    "            elif gpu_series == 'Max':\n",
    "                os.environ['yaml_file'] = f\"{current_dir}/profiling/ai_reference_models_tensorflow_max_gpu.yaml\"\n",
    "            elif gpu_series == 'Arc':\n",
    "                os.environ['yaml_file'] = f\"{current_dir}/profiling/ai_reference_models_tensorflow_arc_gpu.yaml\"\n",
    "            print(\"TensorFlow GPU packages installed.\")\n",
    "\n",
    "else:\n",
    "    raise Exception(\"Please rerun the selections to ensure correct installations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the second model\n",
    "This notebook helps you compare the performance of two models listed in the supported models. Select the first model to run and compare. (If the environment variable MODEL_1_INDEX is set, we'll use that instead of prompting for input.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "config_2 = AIReferenceConfigFile(os.environ['yaml_file'], os.getcwd() + '/..')\n",
    "notebook_root = config_2.notebook_root\n",
    "%cd $notebook_root\n",
    "selected_model = config_2.model_selection()\n",
    "print(selected_model)\n",
    "selected_model = config_2.device_specific(selected_model, general_config_2.hardware_dropdown.value, os.environ['yaml_file'], selected_framework)\n",
    "os.environ['PRECISION'] = config_2.precision\n",
    "if selected_framework == 'TensorFlow' and selected_hardware == 'CPU':\n",
    "    selected_script = config_2.script\n",
    "else:\n",
    "    os.environ['TEST_MODE'] = config_2.test_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Setup\n",
    "The following cell checks for additional environment variables that needs to be specified per model specification. \n",
    "\n",
    "Then checks for additional files, libraries, and configurations that needs to be installed per model specification. Commands are installed in a chronological dependency order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "ai_reference_root = config_2.ai_root\n",
    "%cd $ai_reference_root\n",
    "\n",
    "for export in selected_model['exports']:\n",
    "    env_name = export.split(' ')[0]\n",
    "    env_value = export.split(' ')[1]\n",
    "    if env_value == '-i':\n",
    "        env_value = input(f'Please provide the path for the following environment variable {env_name}: ', )\n",
    "    os.environ[env_name] = os.path.expandvars(env_value)\n",
    "\n",
    "    print(\"Assigned environment variable \", env_name, \" : \", os.environ[env_name])\n",
    "\n",
    "for cmd in selected_model['additional-commands']:\n",
    "    if 'os.environ' in cmd: exec(cmd)\n",
    "    else : subprocess.call(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Retrieve the AI reference root from environment variables\n",
    "ai_reference_root = os.environ.get('AIReferenceRoot')\n",
    "if not ai_reference_root:\n",
    "    raise ValueError(\"Environment variable 'AIReferenceRoot' is not set.\")\n",
    "\n",
    "# Change to the specified directory\n",
    "os.chdir(ai_reference_root)\n",
    "\n",
    "# Process exports from the selected model\n",
    "exports = selected_model.get('exports', [])\n",
    "for export in exports:\n",
    "    try:\n",
    "        # Split the export string into name and value\n",
    "        env_parts = export.split(' ', 1)\n",
    "        if len(env_parts) != 2:\n",
    "            raise ValueError(f\"Invalid export format: {export}\")\n",
    "\n",
    "        env_name, env_value = env_parts\n",
    "        if env_value == '-i':\n",
    "            # Prompt for user input if value is '-i'\n",
    "            env_value = input(f\"Please provide the path for the environment variable '{env_name}': \")\n",
    "\n",
    "        # Expand and set the environment variable\n",
    "        os.environ[env_name] = os.path.expandvars(env_value)\n",
    "        print(f\"Assigned environment variable {env_name}: {os.environ[env_name]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing export '{export}': {e}\")\n",
    "\n",
    "# Process additional commands from the selected model\n",
    "additional_commands = selected_model.get('additional-commands', [])\n",
    "for cmd in additional_commands:\n",
    "    try:\n",
    "        if 'os.environ' in cmd:\n",
    "            # Execute Python commands directly\n",
    "            exec(cmd)\n",
    "        else:\n",
    "            # Execute shell commands\n",
    "            subprocess.call(cmd, shell=True)\n",
    "        print(f\"Executed command: {cmd}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing command '{cmd}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Get the required dataset for the selected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell checks for the second dataset path. If the data-location is already specified, then the notebook will use the dataset path mentioned in ai_reference_models.ini file. If the data-location is not specified in the ai_reference_models.ini, the data downloading option instructions are shown. You must manually download the dataset using these instructions before you can proceed to the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path for dataset directory for the second model:\n",
    "\n",
    "DATASET_DIR': the path where the dataset exists and is downloaded.\n",
    "\n",
    "**ACTION : You need to input the path where the dataset for the second model exists or where you have downloaded it in your system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = input('Input the path where the dataset exists for the first model:')\n",
    "\n",
    "os.environ['DATASET_DIR'] = dataset_path\n",
    "\n",
    "print(\"Data location path:\", os.environ['DATASET_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3: Prepare pre-trained model for the selected model\n",
    "\n",
    "This step checks if the pre-trained model for the selected model exists in the pre-trained directory path. If the pre-trained directory does not exist, then it downloads the pre-trained model for the selected precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "wget_value = config_2.wget\n",
    "\n",
    "pretrain_model_path = config_2.download_pretrained_model(wget=wget_value, current_path=config_2.notebook_root)\n",
    "pretrain_model_path = config_2.uncompress_file(pretrain_model_path, current_path=config_2.notebook_root)\n",
    "if pretrain_model_path:\n",
    "    print('Downloaded the model in:', pretrain_model_path)\n",
    "else:\n",
    "    print('Failed to download the pretrained model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the environment variable for pre-trained model for the second model:\n",
    "\n",
    "'PRETRAINED_MODEL': the path where is the pretrained_model exists and is downloaded.\n",
    "\n",
    "NOTE: You can change the value of 'PRETRAINED_MODEL' by changing its assignment in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"PRETRAINED_MODEL\"]=pretrain_model_path\n",
    "print(\"Pretrain_model_path:\", os.environ[\"PRETRAINED_MODEL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.4: Set the log directory or output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'OUTPUT_DIR': the output directory path where model output logs are collected.\n",
    "\n",
    "The default directory name for the output logs is \"logs\" in the current working directory. You can change this directory name by replacing the value assigned to log_directory in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "log_directory= config_2.notebook_root + os.sep + \"logs\"\n",
    "print(log_directory)\n",
    "\n",
    "os.environ['OUTPUT_DIR']=log_directory\n",
    "print(\"Output directory path is:\", os.environ['OUTPUT_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.5: Run the second model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**if BATCH_SIZE is specified per model specification, set it for optimal batch size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "if selected_model['set-batch-size']['cores']:\n",
    "    import subprocess\n",
    "\n",
    "    # Run the shell command to get the number of cores\n",
    "    output = subprocess.check_output(\"lscpu | grep 'Core(s) per socket' | awk '{print $4}'\", shell=True)\n",
    "\n",
    "    # Decode the byte string output into a regular Python string\n",
    "    cores = int(output.decode(\"utf-8\").strip())\n",
    "\n",
    "    cores = eval(selected_section['set-batch-size']['expr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPTIONAL: You can change the batch size from the model's default. For online_inference,  set batch_size value to be 1.** \n",
    "\n",
    "**Run the next cell if you want to change the batch-size, other skip running the next cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "batch_size= input('Set the value for batch size that you want to run: ')\n",
    "os.environ[\"BATCH_SIZE\"]=batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the second model using the quickstart script configured in the ai_reference_models.ini file, and save output logs to the selected log directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Ensure the AI Reference Root is set and navigate to it\n",
    "ai_reference_root = os.environ.get('AIReferenceRoot', None)\n",
    "if not ai_reference_root or not os.path.isdir(ai_reference_root):\n",
    "    raise FileNotFoundError(\"AIReferenceRoot environment variable is not set or points to an invalid directory.\")\n",
    "os.chdir(ai_reference_root)\n",
    "\n",
    "# Get the YAML file name from environment variables\n",
    "yaml_file = os.environ.get('yaml_file', None)\n",
    "if not yaml_file:\n",
    "    raise ValueError(\"yaml_file environment variable is not set.\")\n",
    "\n",
    "# Debugging: Print the YAML file value\n",
    "print(f\"yaml_file: {yaml_file}\")\n",
    "\n",
    "# Construct the config path\n",
    "configpath = os.path.join(ai_reference_root, \"notebooks\", yaml_file)\n",
    "\n",
    "# Debugging: Print the full path to the YAML file\n",
    "print(f\"Constructed configpath: {configpath}\")\n",
    "\n",
    "# Check if the configuration file exists\n",
    "if not os.path.isfile(configpath):\n",
    "    raise FileNotFoundError(f\"Configuration file not found: {configpath}\")\n",
    "\n",
    "config_2 = AIReferenceConfigFile(os.environ['yaml_file'], os.getcwd() + '/..')\n",
    "# Build log name\n",
    "parts = config_2.model_name.split()\n",
    "log_name = '-'.join(parts) + \".log\"\n",
    "\n",
    "# Check for hardware and framework combination\n",
    "if general_config_2.hardware_dropdown.value == 'CPU' and general_config_2.framework_dropdown.value == 'TensorFlow':\n",
    "    # Build command for TensorFlow CPU workload\n",
    "    run_workload = f\"models_v2/{config_2.framework}/{config_2.model_name}/{config_2.mode}/cpu/{config_2.script}\"\n",
    "    log_name = f\"{config_2.model_name}-{config_2.framework}-cpu.log\"\n",
    "    cmd = f\"./{run_workload} precision={config_2.precision} | tee {log_directory}/{log_name}\"\n",
    "\n",
    "    print(\"Running:\", cmd)\n",
    "    subprocess.call(cmd, shell=True)\n",
    "\n",
    "else:\n",
    "    # Construct the directory path\n",
    "    dir_path = os.path.normpath(f\"models_v2/{config_2.framework}/{config_2.model_name}/{config_2.mode}/{config_2.device}\")\n",
    "\n",
    "    # Debugging: Print the final directory path\n",
    "    print(f\"Final dir_path: {dir_path}\")\n",
    "\n",
    "    if not os.path.isdir(dir_path):\n",
    "        raise FileNotFoundError(f\"Directory not found: {dir_path}\")\n",
    "\n",
    "    # Navigate to the directory\n",
    "    os.chdir(dir_path)\n",
    "    print(f\"Running in directory: {dir_path}\")\n",
    "\n",
    "    # Run setup and model scripts\n",
    "    subprocess.call(\"bash ./setup.sh\", shell=True)\n",
    "    subprocess.call(\"bash ./run_model.sh\", shell=True)\n",
    "\n",
    "    # Navigate back to the previous directory\n",
    "    os.chdir(ai_reference_root)\n",
    "\n",
    "# Navigate back to the original directory (AI Reference Root)\n",
    "os.chdir(ai_reference_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.5 Get the throughput or accuracy of the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Throughput of second workload:\n",
    "# Split the model_name into individual parts\n",
    "import re, statistics\n",
    "try:\n",
    "    with open(f'{log_directory}/{log_name}', 'r') as file:\n",
    "        print(\"DEBUGGING: FILE DIRECTORY:\", f'{log_directory}/{log_name}')\n",
    "        file_content = file.read()\n",
    "        throughput_matches = re.findall(r'Throughput[^:]*:\\s*(\\d+\\.\\d+)\\s+fps', file_content)\n",
    "        accuracy_matches = re.findall(r'Accuracy[^:]*:\\s*(\\d+\\.\\d+)', file_content)\n",
    "        if throughput_matches:\n",
    "            throughput_matches = [float(x) for x in throughput_matches]\n",
    "            throughput_value = float(statistics.mean(throughput_matches))\n",
    "            print(f'Throughput: {throughput_value} fps')\n",
    "        else:\n",
    "            print('Throughput not found in the file.')\n",
    "        if accuracy_matches:\n",
    "            accuracy_matches = [float(x) for x in accuracy_matches]\n",
    "            accuracy_value = float(statistics.mean(accuracy_matches))\n",
    "            print(f'Accuracy: {accuracy_value}')\n",
    "        else:\n",
    "            print('Accuracy not found in the file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compare performance results and plot a comparison chart for the two models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the results (throughput/accuracy) of the two models for comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Throughput of\", model_1_name, \": \", Throughput_of_workload_1)\n",
    "print(\"Throughput of\", model_2_name, \": \", Throughput_of_workload_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a chart for comparision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Define your data\n",
    "categories = [model_1_name.split(' ')[0] + selected_precision, model_2_name.split(' ')[0] + selected_precision_2]\n",
    "\n",
    "# float array expected for charts.\n",
    "values = [float(Throughput_of_workload_1), float(Throughput_of_workload_2)]\n",
    "\n",
    "\n",
    "# Generate a list of colors for each bar\n",
    "colors = ['blue', 'orange']\n",
    "\n",
    "\n",
    "print(categories, values, colors)\n",
    "\n",
    "ax.bar(x=categories, height=values, color=colors)\n",
    "ax.set_ylabel(\"Throughput\")\n",
    "ax.set_title(\"Throughput by each model\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
