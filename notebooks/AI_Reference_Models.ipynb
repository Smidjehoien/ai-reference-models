{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Intel速 AI Reference Models Jupyter Notebook\n",
    "\n",
    "This Jupyter notebook helps you choose and run a comparison between two models from the [Intel速 AI Reference Models repo](https://github.com/IntelAI/models) using Intel速 Optimizations for TensorFlow*. When you run the notebook, it installs required package dependencies, displays information about your platform, lets you choose the two models to compare, runs those models, and finally displays a performance comparison chart. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_1'></a>\n",
    "# Step 1: Display Platform Information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Tensorflow and required dependencies for the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib ipykernel psutil pandas cxxfilt gitpython \n",
    "!pip install intel-tensorflow\n",
    "!pip install gcg\n",
    "!python3 -m pip install gitpython\n",
    "!pip install prettytable\n",
    "!pip install --upgrade matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Set the path for the AI reference models, assumed to be the current working directory, and the path for the utility functions directory inside the cloned Intel速 AI Reference Models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# If default path does not work, change AIReferenceRoot path according to your environment\n",
    "current_path = os.getcwd()\n",
    "os.environ['AIReferenceRoot'] = os.path.dirname(current_path) + \"/\"\n",
    "os.environ['ProfileUtilsRoot'] = os.environ['AIReferenceRoot'] + \"notebooks/profiling/\"\n",
    "print(\"Path for the AI Reference Models root is: \", os.environ['AIReferenceRoot'])\n",
    "print(\"Path for utility functions directory is: \", os.environ['ProfileUtilsRoot'])\n",
    "\n",
    "# Check for mandatory python scripts after AIReferenceRoot and ProfileUtilsRoot are assigned\n",
    "import os\n",
    "current_path = os.getcwd()\n",
    "benchmark_path = os.environ['AIReferenceRoot'] + \"benchmarks/launch_benchmark.py\"\n",
    "if os.path.exists(benchmark_path) == True:\n",
    "    print(benchmark_path)\n",
    "else:\n",
    "    print(\"ERROR! Can't find benchmark/launch_benchmark.py script!\")\n",
    "\n",
    "profile_utils_path = os.environ['ProfileUtilsRoot'] + \"profile_utils.py\"\n",
    "if os.path.exists(profile_utils_path) == True:\n",
    "    print(profile_utils_path)\n",
    "else:\n",
    "    print(\"ERROR! Can't find profile_utils.py script!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print information about the platform specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profiling.profile_utils import PlatformUtils\n",
    "plat_utils = PlatformUtils()\n",
    "plat_utils.dump_platform_info()\n",
    "\n",
    "\n",
    "# Import AI Reference models CPU info\n",
    "import sys\n",
    "sys.path.append(os.environ['AIReferenceRoot']+os.sep+'benchmarks/common/')\n",
    "from platform_util import PlatformUtil \n",
    "cpu_info = PlatformUtil(\"\")\n",
    "\n",
    "# Print Tensorflow version\n",
    "import tensorflow as tf\n",
    "print (\"We are using Tensorflow version\", tf.__version__)\n",
    "\n",
    "# Display the CPU info\n",
    "import os\n",
    "numa_nodes = cpu_info.numa_nodes\n",
    "print(\"CPU count per socket:\" , cpu_info.cores_per_socket ,\" \\nSocket count:\", cpu_info.sockets, \" \\nNuma nodes:\",numa_nodes)\n",
    "if numa_nodes > 0:\n",
    "    socket_number = 1\n",
    "    cpu_count = cpu_info.cores_per_socket\n",
    "    inter_thread = 1\n",
    "else:\n",
    "    # on non-numa machine, we should use all the cores and don't use numactl\n",
    "    socket_number = -1\n",
    "    cpu_count = cpu_info.cores_per_socket * cpu_info.sockets\n",
    "    inter_thread = cpu_info.sockets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run the first model\n",
    "\n",
    "This notebook helps you compare the performance of two models listed in the supported models. Select the first model to run and compare.  (If the environment variable MODEL_1_INDEX is set, we'll use that instead of prompting for input.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Display all the supported models and select first  model to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the list of models is displayed, select one by entering the model index number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profiling.profile_utils import AIReferenceConfigFile\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "config = AIReferenceConfigFile()\n",
    "sections = config.read_supported_section()\n",
    "\n",
    "# Create a table with headers\n",
    "models_table = PrettyTable([\"Index\", \"Model Name\", \"Framework\", \"Mode\", \"Script Type\", \"Precision\"])\n",
    "\n",
    "# Iterate through the sections and add rows to the models table:\n",
    "for index, section in enumerate(sections):\n",
    "    split_section = section.split()\n",
    "\n",
    "    if len(split_section) >= 5:\n",
    "        modelname = split_section[0]\n",
    "        framework = split_section[1]\n",
    "        mode = split_section[2]\n",
    "        script_type = split_section[3]\n",
    "        precision = split_section[4]\n",
    "    \n",
    "        models_table.add_row([index, modelname, framework, mode, script_type, precision])\n",
    "\n",
    "print(\"Supported Models: \")\n",
    "print(models_table)\n",
    "\n",
    "# use the \"MODEL_1_INDEX\" environment variable value if it exists.\n",
    "import os\n",
    "env_model_1_index=os.environ.get('MODEL_1_INDEX', '')\n",
    "if env_model_1_index != '':\n",
    "    model_1_index= int(env_model_1_index)\n",
    "else:\n",
    "    ## USER INPUT\n",
    "    model_1_index= int(input('Input a index number of a model: '))\n",
    "\n",
    "# List out the selected model name\n",
    "if model_1_index >= len(sections):\n",
    "    print(\"ERROR! Input a model_index value between 0 and \", len(sections))\n",
    "else:\n",
    "    model_1_name=sections[model_1_index]\n",
    "\n",
    "# Prints out model name\n",
    "print(\"First model is: \", model_1_name)\n",
    "\n",
    "# Set the environment variable for precision to run the quickstart scripts\n",
    "configvals = []\n",
    "\n",
    "# Get the parameters from config\n",
    "configvals=config.read_config(model_1_name)\n",
    "os.environ['PRECISION']=config.precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Get the required dataset for the selected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell checks the dataset path. If the data-location is already specified, then the notebook will use the dataset path mentioned in ai_reference_models.ini file. If the data-location is not specified in the ai_reference_models.ini, the data downloading option instructions are shown. You must manually download the dataset using these instructions before you can proceed to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Get the parameters from config\n",
    "config = AIReferenceConfigFile()\n",
    "config.read_config(model_1_name)\n",
    "data_download_path=''\n",
    "model_source_dir=''\n",
    "if config.data_download != '': #and config.data_location == '':\n",
    "    print(\"\\nFollow these instructions to get the data : \")\n",
    "    if config.data_download != '':\n",
    "        val = config.read_value_from_section(model_1_name, 'data-download')\n",
    "    print(val)\n",
    "    # use the \"DATA_DOWNLOAD_PATH\" environment variable value if it exists.\n",
    "    env_data_download_path=os.environ.get('DATA_DOWNLOAD_PATH', '')\n",
    "    if env_data_download_path != '':\n",
    "        data_download_path= env_data_download_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path for dataset directory for the first model:\n",
    "\n",
    "DATASET_DIR': the path where the dataset exists and is downloaded.\n",
    "\n",
    "**ACTION : You need to input the path where the dataset for the first model exists or where you have downloaded it in your system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = input('Input the path where the dataset exists for the first model:')\n",
    "\n",
    "os.environ['DATASET_DIR'] = dataset_path\n",
    "print(\"Data location path:\", os.environ['DATASET_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3: Prepare pre-trained model for the selected model\n",
    "\n",
    "This step checks if the pre-trained model for the selected model exists in the pre-trained directory path. If the pre-trained directory does not exist, then it downloads the pre-trained model for the selected precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = AIReferenceConfigFile()\n",
    "configvals = []\n",
    "\n",
    "# Get the parameters from config\n",
    "configvals=config.read_config(model_1_name)\n",
    "\n",
    "# Get the pre-trained model file\n",
    "if config.wget != '':\n",
    "    pretrain_model_path = config.download_pretrained_model(current_path=current_path)\n",
    "    pretrain_model_path = config.uncompress_file(pretrain_model_path, current_path=current_path)\n",
    "\n",
    "# Add custom arguments\n",
    "if config.custom_args != '':\n",
    "    configvals.append(\"--\")\n",
    "    custom_config = config.parsing_custom_args(model_1_name, config.custom_args)\n",
    "    configvals = configvals + custom_config\n",
    "    \n",
    "# Combine common parameters and config parameters\n",
    "params = configvals    \n",
    "    \n",
    "sys.argv=[benchmark_path]+params\n",
    "print(sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the environment variable for pre-trained model for the first model:\n",
    "\n",
    "'PRETRAINED_MODEL': the path where is the pretrained_model exists and is downloaded.\n",
    "\n",
    "NOTE: You can change the value of 'PRETRAINED_MODEL' by changing its assignment in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PRETRAINED_MODEL\"]=pretrain_model_path\n",
    "print(\"Pretrain_model_path:\", os.environ[\"PRETRAINED_MODEL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.4: Set the log directory or output directory\n",
    "\n",
    "'OUTPUT_DIR': the output directory path where model output logs are collected.\n",
    "\n",
    "The default directory name for the output logs is \\\"logs\\\" in the current working directory. You can change this directory name by replacing the value assigned to log_directory in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the log directory/output directory to store the logs\n",
    "log_directory=os.getcwd() + os.sep + \"logs\"\n",
    "print(log_directory)\n",
    "\n",
    "#Set output-dir directory\n",
    "if log_directory !='':\n",
    "    configvals.append(\"--output-dir\")\n",
    "    configvals.append(log_directory)\n",
    "\n",
    "os.environ['OUTPUT_DIR']=log_directory\n",
    "print(\"Output directory path is:\", os.environ['OUTPUT_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.5:  Run the first Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPTIONAL: You can change the batch size from the model's default. For online_inference,  set batch_size value to be 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= int(input('Set the value for batch size that you want to run: '))\n",
    "os.environ[\"BATCH SIZE\"]=batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the first model using the quickstart script configured in the ai_reference_models.ini file, and save output logs to the selected log directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AIReferenceConfigFile()\n",
    "\n",
    "# Get the parameters from config\n",
    "config.read_config(model_1_name)\n",
    "\n",
    "# Split the model_name into individual parts\n",
    "parts = model_1_name.split()\n",
    "\n",
    "# Join the parts using hyphens as the separator\n",
    "log_name = '-'.join(parts)\n",
    "log_name = log_name + \".log\"\n",
    "\n",
    "ai_reference_root = os.environ.get('AIReferenceRoot')\n",
    "\n",
    "%cd $ai_reference_root\n",
    "run_workload = (\"quickstart/\" + config.ai_type + \"/\" + config.framework + \"/\"+ config.model_name + \"/\"\n",
    "                + config.mode + \"/\" + config.device +\"/\" + config.script ) \n",
    "\n",
    "!./$run_workload | tee $log_directory/{log_name}\n",
    "\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.6 Get the throughput or accuracy of the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throughput of first workload:\n",
    "# Split the model_name into individual parts\n",
    "parts_1 = model_1_name.split()\n",
    "\n",
    "# Join the parts using hyphens as the separator\n",
    "log_1_name = '-'.join(parts_1)\n",
    "log_1_name = log_1_name + \".log\"\n",
    "\n",
    "!grep -A 1 \"Throughput summary:\" $log_directory/{log_1_name} | tail -n 1\n",
    "\n",
    "import subprocess\n",
    "# Run the grep command and capture its output\n",
    "try:\n",
    "    grep_output = subprocess.check_output(f'grep -A 1 \"Throughput summary:\" {log_directory}/{log_1_name} | tail -n 1; grep -A 1 \"Summary total images/sec:\" {log_directory}/{log_1_name} | tail -n 1', shell=True, universal_newlines=True)\n",
    "except subprocess.CalledProcessError:\n",
    "    grep_output = \"Pattern not found in the file.\"\n",
    "\n",
    "# Print or use the captured output as needed\n",
    "print(\"Throughput of \", model_1_name, \": \", grep_output.strip())  # Remove leading/trailing whitespace\n",
    "\n",
    "# Store the captured output in a variable for further use\n",
    "Throughput_of_workload_1 = grep_output.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Select and run the second model\n",
    "\n",
    "Let's now run a second model and compare its performance with the first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1 Select another model for comparision\n",
    "\n",
    "After the list of models is displayed, select one by entering the model index number. (If the environment variable MODEL_2_INDEX is set, we'll use that instead of prompting for input.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Supported Models: \")\n",
    "print(models_table)\n",
    "\n",
    "# use the \"MODEL_2_INDEX\" environment variable value if it exists.\n",
    "env_model_2_index=os.environ.get('MODEL_2_INDEX', '')\n",
    "if env_model_2_index != '':\n",
    "    model_2_index= int(env_model_2_index)\n",
    "else:\n",
    "    ## USER INPUT\n",
    "    model_2_index= int(input('Input a index number of second model: '))\n",
    "\n",
    "# List out the selected model name\n",
    "if model_2_index >= len(sections):\n",
    "    print(\"ERROR! Input a model_index value between 0 and \", len(sections))\n",
    "else:\n",
    "    model_2_name=sections[model_2_index]\n",
    "\n",
    "# Prints out model name\n",
    "print(\"Second model is: \", model_2_name)\n",
    "\n",
    "# Set the environment variable for precision to run the quickstart scripts\n",
    "configvals = []\n",
    "\n",
    "# Get the parameters from config\n",
    "configvals=config.read_config(model_2_name)\n",
    "os.environ['PRECISION']=config.precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Get the required dataset for the selected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell checks for the second dataset path. If the data-location is already specified, then the notebook will use the dataset path mentioned in ai_reference_models.ini file. If the data-location is not specified in the ai_reference_models.ini, the data downloading option instructions are shown. You must manually download the dataset using these instructions before you can proceed to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parameters from config\n",
    "config = AIReferenceConfigFile()\n",
    "config.read_config(model_2_name)\n",
    "data_download_path=''\n",
    "model_source_dir=''\n",
    "if config.data_download != '' and config.data_location == '':\n",
    "    print(\"\\nFollow these instructions to get the data : \")\n",
    "    if config.data_download != '':\n",
    "        val = config.read_value_from_section(model_2_name, 'data-download')\n",
    "    print(val)\n",
    "    # use the \"DATA_DOWNLOAD_PATH\" environment variable value if it exists.\n",
    "    env_data_download_path=os.environ.get('DATA_DOWNLOAD_PATH', '')\n",
    "    if env_data_download_path != '':\n",
    "        data_download_path= env_data_download_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path for dataset directory for the second model:\n",
    "\n",
    "DATASET_DIR': the path where the dataset exists and is downloaded.\n",
    "\n",
    "**ACTION : You need to input the path where the dataset for the second model exists or where you have downloaded it in your system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = input('Input the path where the dataset exists for the second model:')\n",
    "\n",
    "os.environ['DATASET_DIR'] = dataset_path\n",
    "print(\"Data location path:\", os.environ['DATASET_DIR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3: Prepare pre-trained model for the selected model\n",
    "\n",
    "This step checks if the pre-trained model for the selected model exists in the pre-trained directory path. If the pre-trained directory does not exist, then it downloads the pre-trained model for the selected precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AIReferenceConfigFile()\n",
    "configvals = []\n",
    "\n",
    "# Get the parameters from config\n",
    "configvals=config.read_config(model_2_name)\n",
    "\n",
    "# Set the log directory/output directory to store the logs\n",
    "log_directory=os.getcwd() + os.sep + \"logs\"\n",
    "print(log_directory)\n",
    "\n",
    "# Get the pre-trained model file\n",
    "if config.wget != '':\n",
    "    pretrain_model_path = config.download_pretrained_model(current_path=current_path)\n",
    "    pretrain_model_path = config.uncompress_file(pretrain_model_path, current_path=current_path)\n",
    "    \n",
    "#Set output-dir directory\n",
    "if log_directory !='':\n",
    "    configvals.append(\"--output-dir\")\n",
    "    configvals.append(log_directory)\n",
    "\n",
    "# Add custom arguments\n",
    "if config.custom_args != '':\n",
    "    configvals.append(\"--\")\n",
    "    custom_config = config.parsing_custom_args(model_2_name, config.custom_args)\n",
    "    configvals = configvals + custom_config\n",
    "    \n",
    "# Combine common parameters and config parameters\n",
    "params = configvals    \n",
    "    \n",
    "sys.argv=[benchmark_path]+params\n",
    "print(sys.argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the environment variable for pre-trained model for the second model:\n",
    "\n",
    "'PRETRAINED_MODEL': the path where is the pretrained_model exists and is downloaded.\n",
    "\n",
    "NOTE: You can change the value of 'PRETRAINED_MODEL' by changing its assignment in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PRETRAINED_MODEL\"]=pretrain_model_path\n",
    "print(\"Pretrain_model_path:\", os.environ[\"PRETRAINED_MODEL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.4: Run the second model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPTIONAL: You can change the batch size from the model's default. For online_inference,  set batch_size value to be 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= int(input('Set the value for batch size that you want to run: '))\n",
    "os.environ[\"BATCH SIZE\"]=batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the second model using the quickstart script configured in the ai_reference_models.ini file, and save output logs to the selected log directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AIReferenceConfigFile()\n",
    "\n",
    "# Get the parameters from config\n",
    "config.read_config(model_2_name)\n",
    "\n",
    "# Split the model_name into individual parts\n",
    "parts = model_2_name.split()\n",
    "\n",
    "# Join the parts using hyphens as the separator\n",
    "log_name = '-'.join(parts)\n",
    "log_name = log_name + \".log\"\n",
    "\n",
    "ai_reference_root = os.environ.get('AIReferenceRoot')\n",
    "\n",
    "%cd $ai_reference_root\n",
    "run_workload = (\"quickstart/\" + config.ai_type + \"/\" + config.framework + \"/\"+ config.model_name + \"/\"\n",
    "                + config.mode + \"/\" + config.device +\"/\" + config.script ) \n",
    "\n",
    "!./$run_workload | tee $log_directory/{log_name}\n",
    "\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.5 Get the throughput or accuracy of the second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Throughput of second workload:\n",
    "# Split the model_name into individual parts\n",
    "parts_2 = model_2_name.split()\n",
    "\n",
    "# Join the parts using hyphens as the separator\n",
    "log_2_name = '-'.join(parts_2)\n",
    "log_2_name = log_2_name + \".log\"\n",
    "\n",
    "!grep -A 1 \"Throughput summary:|Summary total images/sec:\" $log_directory/{log_2_name} | tail -n 1\n",
    "\n",
    "# Run the grep command and capture its output\n",
    "try:\n",
    "    grep_output = subprocess.check_output(f'grep -A 1 \"Throughput summary:\" {log_directory}/{log_2_name} | tail -n 1; grep -A 1 \"Summary total images/sec:\" {log_directory}/{log_2_name} | tail -n 1', shell=True, universal_newlines=True)\n",
    "except subprocess.CalledProcessError:\n",
    "    grep_output = \"Pattern not found in the file.\"\n",
    "\n",
    "# Print or use the captured output as needed\n",
    "print(\"Throughput of \", model_2_name, \": \", grep_output.strip())  # Remove leading/trailing whitespace\n",
    "\n",
    "# Store the captured output in a variable for further use\n",
    "Throughput_of_workload_2 = grep_output.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Compare performance results and plot a comparison chart for the two models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the results (throughput/accuracy) of the two models for comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Throughput of\", model_1_name, \": \", Throughput_of_workload_1)\n",
    "print(\"Throughput of\", model_2_name, \": \", Throughput_of_workload_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a chart for comparision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Define your data\n",
    "categories = [model_1_name, model_2_name]\n",
    "values = [Throughput_of_workload_1, Throughput_of_workload_2]\n",
    "\n",
    "# Generate a list of colors for each bar\n",
    "colors = ['blue', 'orange']\n",
    "\n",
    "bars = plt.scatter(model_1_name,Throughput_of_workload_1 , label=model_1_name, color='blue')\n",
    "bars = plt.scatter(model_2_name,Throughput_of_workload_2 , label=model_2_name, color='orange')\n",
    "\n",
    "# Add labels and a title\n",
    "plt.xlabel('Workloads')\n",
    "plt.ylabel('Throughput')\n",
    "plt.title('Bar Chart of Two workloads')\n",
    "\n",
    "# Set the x-axis ticks and labels\n",
    "plt.xticks(range(len(categories)), [])\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
