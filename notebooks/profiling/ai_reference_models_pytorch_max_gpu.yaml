- name: resnet50v1_5 pytorch inference
  model-name: resnet50v1_5
  mode: inference
  framework: pytorch
  device: gpu
  precision: ["BF16", "TF32"]
  data-location:
  data-download: Default is dummy dataset. ImageNet is recommended, the download link is https://image-net.org/challenges/LSVRC/2012/2012-downloads.php."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE False"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: resnet50v1_5_multi_tile pytorch inference
  model-name: resnet50v1_5_multi_tile
  mode: inference
  framework: pytorch
  device: gpu
  precision: ["BF16", "TF32"]
  data-location:
  data-download: Default is dummy dataset. ImageNet is recommended, the download link is https://image-net.org/challenges/LSVRC/2012/2012-downloads.php."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE True"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: resnet50v1_5 pytorch training
  model-name: resnet50v1_5
  mode: training
  framework: pytorch
  device: gpu
  precision: ["BF16", "TF32", "FP32"]
  data-location:
  data-download: Default is dummy dataset. ImageNet is recommended, the download link is https://image-net.org/challenges/LSVRC/2012/2012-downloads.php."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE False"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: resnet50v1_5_multi_tile pytorch training
  model-name: resnet50v1_5_multi_tile
  mode: training
  framework: pytorch
  device: gpu
  precision: ["BF16", "TF32", "FP32"]
  data-location:
  data-download: Default is dummy dataset. ImageNet is recommended, the download link is https://image-net.org/challenges/LSVRC/2012/2012-downloads.php."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE True"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: distilbert pytorch inference
  model-name: distilbert
  mode: inference
  framework: pytorch
  device: gpu
  precision: ["FP32", "BF16", "FP16", "TF32"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/blob/master/models_v2/pytorch/distilbert/inference/gpu/README.md#dataset."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE False"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: distilbert_multi_tile pytorch inference
  model-name: distilbert_multi_tile
  mode: inference
  framework: pytorch
  device: gpu
  precision: ["FP32", "BF16", "FP16", "TF32"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/blob/master/models_v2/pytorch/distilbert/inference/gpu/README.md#dataset."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE True"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: bert_large pytorch inference
  model-name: bert_large
  mode: inference
  framework: pytorch
  device: gpu
  precision: ["FP32", "BF16", "FP16"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/tree/master/models_v2/pytorch/bert_large/inference/gpu#datasets."
  additional-commands: [
    "mkdir $(pwd)/squad_large_finetuned_checkpoint",
    "wget -c https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json -O $(pwd)/squad_large_finetuned_checkpoint/config.json",
    "wget -c https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/pytorch_model.bin  -O $(pwd)/squad_large_finetuned_checkpoint/pytorch_model.bin",
    "wget -c https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/tokenizer.json -O $(pwd)/squad_large_finetuned_checkpoint/tokenizer.json",
    "wget -c https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/tokenizer_config.json -O $(pwd)/squad_large_finetuned_checkpoint/tokenizer_config.json",
    "wget -c https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt -O $(pwd)/squad_large_finetuned_checkpoint/vocab.txt"
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE False",
    "BERT_WEIGHT $(pwd)/squad_large_finetuned_checkpoint"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: bert_large_multi_tile pytorch inference
  model-name: bert_large_multi_tile
  mode: inference
  framework: pytorch
  device: gpu
  precision: ["FP32", "BF16", "FP16"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/tree/master/models_v2/pytorch/bert_large/inference/gpu#datasets."
  additional-commands: [
    "mkdir $(pwd)/squad_large_finetuned_checkpoint",
    "wget -c https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/config.json -O $(pwd)/squad_large_finetuned_checkpoint/config.json",
    "wget -c https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/pytorch_model.bin  -O $(pwd)/squad_large_finetuned_checkpoint/pytorch_model.bin",
    "wget -c https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/tokenizer.json -O $(pwd)/squad_large_finetuned_checkpoint/tokenizer.json",
    "wget -c https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/tokenizer_config.json -O $(pwd)/squad_large_finetuned_checkpoint/tokenizer_config.json",
    "wget -c https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad/resolve/main/vocab.txt -O $(pwd)/squad_large_finetuned_checkpoint/vocab.txt"
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE True",
    "BERT_WEIGHT $(pwd)/squad_large_finetuned_checkpoint"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: bert_large pytorch training
  model-name: bert_large
  mode: training
  framework: pytorch
  device: gpu
  precision: ["BF16", "FP32", "TF32"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/blob/master/models_v2/pytorch/bert_large/training/gpu/README.md#dataset."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE False"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: bert_large_multi_tile pytorch training
  model-name: bert_large_multi_tile
  mode: training
  framework: pytorch
  device: gpu
  precision: ["BF16", "FP32", "TF32"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/blob/master/models_v2/pytorch/bert_large/training/gpu/README.md#dataset."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE True"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: DLRM_v2 pytorch training
  model-name: torchrec_dlrm
  mode: training
  framework: pytorch
  device: gpu
  precision: ["BF16", "FP32", "TF32"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/tree/master/models_v2/pytorch/torchrec_dlrm/training/gpu#prepare-dataset."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE True"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: 3d_unet pytorch inference
  model-name: 3d_unet
  mode: inference
  framework: pytorch
  device: gpu
  precision: ["FP16", "INT8", "FP32"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/tree/master/models_v2/pytorch/3d_unet/inference/gpu#prepare-dataset."
  additional-commands: [
    "Please follow the instructions to download the following and only then proceed",
    "https://github.com/IntelAI/models/blob/master/models_v2/pytorch/3d_unet/inference/gpu/README.md#prepare-data-file"
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE False"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: 3d_unet_multi_tile pytorch inference
  model-name: 3d_unet_multi_tile
  mode: inference
  framework: pytorch
  device: gpu
  precision: ["FP16", "INT8", "FP32"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/tree/master/models_v2/pytorch/3d_unet/inference/gpu#prepare-dataset."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE True"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: stable_diffusion pytorch inference
  model-name: stable_diffusion
  mode: inference
  framework: pytorch
  device: gpu
  precision: ["FP16", "FP32"]
  data-location:
  data-download: The scripts will download the dataset automatically. You can give random path when prompted to give the path for the dataset."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE False"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: stable_diffusion_multi_tile pytorch inference
  model-name: stable_diffusion_multi_tile
  mode: inference
  framework: pytorch
  device: gpu
  precision: ["FP16", "FP32"]
  data-location:
  data-download: The scripts will download the dataset automatically. You can give random path when prompted to give the path for the dataset."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE True"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: rnnt pytorch inference
  model-name: rnnt
  mode: inference
  framework: pytorch
  device: gpu
  precision: ["FP16", "FP32", "BF16"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/tree/master/models_v2/pytorch/rnnt/inference/gpu#prepare-dataset."
  additional-commands: [
    "wget -O $(pwd)/rnnt_ckpt.pt https://zenodo.org/record/3662521/files/DistributedDataParallel_1576581068.9962234-epoch-100.pt?download=1"
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE False",
    "WEIGHT_DIR $(pwd)"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: rnnt_multi_tile pytorch inference
  model-name: rnnt_multi_tile
  mode: inference
  framework: pytorch
  device: gpu
  precision: ["FP16", "FP32", "BF16"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/tree/master/models_v2/pytorch/rnnt/inference/gpu#prepare-dataset."
  additional-commands: [
    "wget -O $(pwd)/rnnt_ckpt.pt https://zenodo.org/record/3662521/files/DistributedDataParallel_1576581068.9962234-epoch-100.pt?download=1"
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE True",
    "WEIGHT_DIR $(pwd)"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: rnnt pytorch training
  model-name: rnnt
  mode: training
  framework: pytorch
  device: gpu
  precision: ["BF16", "FP32", "TF32"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/blob/master/models_v2/pytorch/rnnt/training/gpu/README.md#prepare-dataset."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE True"
  ]
  set-batch-size:
    cores: false
    expr: ""

- name: rnnt_multi_tile pytorch training
  model-name: rnnt_multi_tile
  mode: training
  framework: pytorch
  device: gpu
  precision: ["BF16", "FP32", "TF32"]
  data-location:
  data-download: Please follow the link to download the dataset - https://github.com/IntelAI/models/blob/master/models_v2/pytorch/rnnt/training/gpu/README.md#prepare-dataset."
  additional-commands: [
    ]
  exports: [
    "PLATFORM Max",
    "MULTI_TILE True"
  ]
  set-batch-size:
    cores: false
    expr: ""
