# SSD-MobileNet

The following links have instructions for how to run SSD-MobileNet for the
following modes/precisions:
* [Int8 Inference Instructions](/benchmarks/object_detection/tensorflow/ssd-mobilenet/inference/int8/README.md)
* [FP32 Inference Instructions](/benchmarks/object_detection/tensorflow/ssd-mobilenet/inference/fp32/README.md)
* [BFloat16 Inference Instructions](/benchmarks/object_detection/tensorflow/ssd-mobilenet/inference/bfloat16/README.md)


