---
tf-max-gpu-bert-large-inference:
  image_name: intel/language-modeling:tf-max-gpu-bert-large-inference
  tests:
  - test_name: BERT Large FP16 benchmark
    env_vars:
      PRECISION: fp16
      Tile: 2
      FROZEN_GRAPH: /workspace/tf-max-series-bert-large-inference/frozen_graph/fp32_bert_squad.pb
      PRETRAINED_DIR: /pytorch/wwm_uncased_L-24_H-1024_A-16
      SQUAD_DIR: /pytorch/bert-large-inference/squad_dir
      SCRIPT: quickstart/benchmark.sh
      OUTPUT_DIR: /output/tf-max-gpu-bert-large-inference
      DOCKER_ARGS: --ipc=host --privileged --device=/dev/dri
    volumes:
      OUTPUT_DIR: /output/tf-max-gpu-bert-large-inference
      PRETRAINED_DIR: /pytorch/wwm_uncased_L-24_H-1024_A-16
      SQUAD_DIR: /pytorch/bert-large-inference/squad_dir
  - test_name: BERT Large FP32 benchmark
    env_vars:
      PRECISION: fp32
      
      Tile: 2
      FROZEN_GRAPH: /workspace/tf-max-series-bert-large-inference/frozen_graph/fp32_bert_squad.pb
      PRETRAINED_DIR: /pytorch/wwm_uncased_L-24_H-1024_A-16
      SQUAD_DIR: /pytorch/bert-large-inference/squad_dir
      SCRIPT: quickstart/benchmark.sh
      OUTPUT_DIR: /output/tf-max-gpu-bert-large-inference/fp32
      DOCKER_ARGS: --ipc=host --privileged --device=/dev/dri
    volumes:
      OUTPUT_DIR: /output/tf-max-gpu-bert-large-inference/fp32
      PRETRAINED_DIR: /pytorch/bert-large-inference
      SQUAD_DIR: /pytorch/bert-large-inference/squad_dir
