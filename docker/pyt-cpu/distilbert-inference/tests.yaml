fp32-accuracy:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_accuracy.sh fp32
  env:
    PRECISION: fp32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
fp32-realtime:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_multi_instance_realtime.sh fp32
  env:
    PRECISION: fp32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '4'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
fp32-throughput:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_multi_instance_throughput.sh fp32
  env:
    PRECISION: fp32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
bf32-accuracy:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_accuracy.sh bf32
  env:
    PRECISION: bf32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
bf32-realtime:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_multi_instance_realtime.sh bf32
  env:
    PRECISION: bf32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '4'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
bf32-throughout:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_multi_instance_throughput.sh bf32
  env:
    PRECISION: bf32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
int8-bf16-accuracy:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_accuracy.sh int8-bf16
  env:
    PRECISION: int8-bf16
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
int8-bf16-realtime:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_multi_instance_realtime.sh int8-bf16
  env:
    PRECISION: int8-bf16
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '4'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
int8-bf16-throughput:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_multi_instance_throughput.sh int8-bf16
  env:
    PRECISION: int8-bf16
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
int8-fp32-accuracy:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_accuracy.sh int8-fp32
  env:
    PRECISION: int8-fp32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
int8-fp32-realtime:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_multi_instance_realtime.sh int8-fp32
  env:
    PRECISION: int8-fp32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '4'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
int8-fp32-throughput:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_multi_instance_throughput.sh int8-fp32
  env:
    PRECISION: int8-fp32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
bf16-accuracy:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_accuracy.sh bf16
  env:
    PRECISION: bf16
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
bf16-realtime:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_multi_instance_realtime.sh bf16
  env:
    PRECISION: bf16
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '4'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
bf16-throughput:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_multi_instance_throughput.sh bf16
  env:
    PRECISION: bf16
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
bf32-accuracy:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_accuracy.sh bf32
  env:
    PRECISION: bf32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
bf32-realtime:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_multi_instance_realtime.sh bf32
  env:
    PRECISION: bf32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '4'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
bf32-throughput:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: quickstart/run_multi_instance_throughput.sh bf32
  env:
    PRECISION: bf32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
    TRAIN_SCRIPT: /workspace/pytorch-distilbert-inference/models/language_modeling/pytorch/bert_large/training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/distilbert/SST-2
    EVAL_SCRIPT: /workspace/pytorch-distilbert-inference/quickstart/transformers/examples/pytorch/text-classification/run_glue.py
  volumes:
    - src: /pytorch/distilbert/SST-2
      dst: /pytorch/distilbert/SST-2
    - src: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
      dst: /pytorch/distilbert/distilbert-base-uncased-finetuned-sst-2-english
