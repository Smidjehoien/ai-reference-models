Transformer Realtime inference fp32:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${OS:-ubuntu}-language-translation-tf-transformer-mlperf-inference
  cmd: /bin/bash quickstart/inference_realtime.sh --benchmark-only --num-intra-threads 4 --num-inter-threads 1
  env:
    DATASET_DIR: /tf_dataset/pre-trained-models/transformer_mlperf/data
    KMP_AFFINITY: granularity=fine,verbose,compact,1,0
    OUTPUT_DIR: /output/tf-transformer-mlperf-inference/realtime_fp32
    PRECISION: fp32
    BATCH_SIZE: '1'
    OMP_NUM_THREADS: '4'
  shm_size: 8G
  privileged: true
  init: true
  volumes:
  - src: /tf_dataset/pre-trained-models/transformer_mlperf/data
    dst: /tf_dataset/pre-trained-models/transformer_mlperf/data
  - src: $PWD/output/tf-transformer-mlperf-inference/realtime_fp32
    dst: /output/tf-transformer-mlperf-inference/realtime_fp32
Transformer Realtime inference bf16:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${OS:-ubuntu}-language-translation-tf-transformer-mlperf-inference
  cmd: /bin/bash quickstart/inference_realtime.sh --benchmark-only
  env:
    DATASET_DIR: /tf_dataset/pre-trained-models/transformer_mlperf/data
    KMP_AFFINITY: granularity=fine,verbose,compact,1,0
    OUTPUT_DIR: /output/tf-transformer-mlperf-inference/realtime_bf16
    PRECISION: bfloat16
    BATCH_SIZE: '1'
  shm_size: 8G
  privileged: true
  init: true
  volumes:
  - src: /tf_dataset/pre-trained-models/transformer_mlperf/data
    dst: /tf_dataset/pre-trained-models/transformer_mlperf/data
  - src: $PWD/output/tf-transformer-mlperf-inference/realtime_bf16
    dst: /output/tf-transformer-mlperf-inference/realtime_bf16
Transformer Realtime inference int8:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${OS:-ubuntu}-language-translation-tf-transformer-mlperf-inference
  cmd: /bin/bash quickstart/inference_realtime.sh --benchmark-only
  env:
    DATASET_DIR: /tf_dataset/pre-trained-models/transformer_mlperf/data
    KMP_AFFINITY: granularity=fine,verbose,compact,1,0
    OUTPUT_DIR: /output/tf-transformer-mlperf-inference/realtime_int8
    PRECISION: int8
    BATCH_SIZE: '1'
  shm_size: 8G
  privileged: true
  init: true
  volumes:
  - src: /tf_dataset/pre-trained-models/transformer_mlperf/data
    dst: /tf_dataset/pre-trained-models/transformer_mlperf/data
  - src: $PWD/output/tf-transformer-mlperf-inference/realtime_int8
    dst: /output/tf-transformer-mlperf-inference/realtime_int8
Transformer Throughput bf16:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${OS:-ubuntu}-language-translation-tf-transformer-mlperf-inference
  cmd: /bin/bash quickstart/inference_throughput.sh
  env:
    DATASET_DIR: /tf_dataset/pre-trained-models/transformer_mlperf/data
    KMP_AFFINITY=granularity: fine,verbose,compact,1,0 
    OUTPUT_DIR: /output/tf-transformer-mlperf-inference/throughput_bf16
    PRECISION: bfloat16
    BATCH_SIZE: '448'
  shm_size: 8G
  privileged: true
  init: true
  volumes:
  - src: /tf_dataset/pre-trained-models/transformer_mlperf/data
    dst: /tf_dataset/pre-trained-models/transformer_mlperf/data
  - src: $PWD/output/tf-transformer-mlperf-inference/throughput_bf16
    dst: /output/tf-transformer-mlperf-inference/throughput_bf16
Transformer Throughput fp32:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${OS:-ubuntu}-language-translation-tf-transformer-mlperf-inference
  cmd: /bin/bash quickstart/inference_throughput.sh
  env:
    DATASET_DIR: /tf_dataset/pre-trained-models/transformer_mlperf/data
    KMP_AFFINITY: granularity=fine,verbose,compact,1,0
    OUTPUT_DIR: /output/tf-transformer-mlperf-inference/throughput_fp32
    PRECISION: fp32
    BATCH_SIZE: '448'
  shm_size: 8G
  privileged: true
  init: true
  volumes:
  - src: /tf_dataset/pre-trained-models/transformer_mlperf/data
    dst: /tf_dataset/pre-trained-models/transformer_mlperf/data
  - src: $PWD/output/tf-transformer-mlperf-inference/throughput_fp32
    dst: /output/tf-transformer-mlperf-inference/throughput_fp32
Transformer Throughput int8:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${OS:-ubuntu}-language-translation-tf-transformer-mlperf-inference
  cmd: /bin/bash quickstart/inference_throughput.sh
  env:
    DATASET_DIR: /tf_dataset/pre-trained-models/transformer_mlperf/data
    KMP_AFFINITY: granularity=fine,verbose,compact,1,0
    OUTPUT_DIR: /output/tf-transformer-mlperf-inference/throughput_int8
    PRECISION: int8
    BATCH_SIZE: '448'
  shm_size: 8G
  privileged: true
  init: true
  volumes:
  - src: /tf_dataset/pre-trained-models/transformer_mlperf/data
    dst: /tf_dataset/pre-trained-models/transformer_mlperf/data
  - src: $PWD/output/tf-transformer-mlperf-inference/throughput_int8
    dst: /output/tf-transformer-mlperf-inference/throughput_int8
Transformer Accuracy fp32:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${OS:-ubuntu}-language-translation-tf-transformer-mlperf-inference
  cmd: /bin/bash quickstart/accuracy.sh
  env:
    BATCH_SIZE: '64'
    DATASET_DIR: /tf_dataset/pre-trained-models/transformer_mlperf/data
    OUTPUT_DIR: /output/tf-transformer-mlperf-inference/accuracy_fp32
    PRECISION: fp32
  shm_size: 8G
  privileged: true
  init: true
  volumes:
  - src: /tf_dataset/pre-trained-models/transformer_mlperf/data
    dst: /tf_dataset/pre-trained-models/transformer_mlperf/data
  - src: $PWD/output/tf-transformer-mlperf-inference/accuracy_fp32
    dst: /output/tf-transformer-mlperf-inference/accuracy_fp32
Transformer Accuracy bf16:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${OS:-ubuntu}-language-translation-tf-transformer-mlperf-inference
  cmd: /bin/bash quickstart/accuracy.sh
  env:
    BATCH_SIZE: '64'
    DATASET_DIR: /tf_dataset/pre-trained-models/transformer_mlperf/data
    OUTPUT_DIR: /output/tf-transformer-mlperf-inference/accuracy_bf16
    PRECISION: bfloat16
  shm_size: 8G
  privileged: true
  init: true
  volumes:
  - src: /tf_dataset/pre-trained-models/transformer_mlperf/data
    dst: /tf_dataset/pre-trained-models/transformer_mlperf/data
  - src: $PWD/output/tf-transformer-mlperf-inference/accuracy_bf16
    dst: /output/tf-transformer-mlperf-inference/accuracy_bf16
Transformer Accuracy int8:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${OS:-ubuntu}-language-translation-tf-transformer-mlperf-inference
  cmd: /bin/bash quickstart/accuracy.sh
  env:
    BATCH_SIZE: '64'
    DATASET_DIR: /tf_dataset/pre-trained-models/transformer_mlperf/data
    OUTPUT_DIR: /output/tf-transformer-mlperf-inference/accuracy_int8
    PRECISION: int8
  shm_size: 8G
  privileged: true
  init: true
  volumes:
  - src: /tf_dataset/pre-trained-models/transformer_mlperf/data
    dst: /tf_dataset/pre-trained-models/transformer_mlperf/data
  - src: $PWD/output/tf-transformer-mlperf-inference/accuracy_int8
    dst: /output/tf-transformer-mlperf-inference/accuracy_int8
