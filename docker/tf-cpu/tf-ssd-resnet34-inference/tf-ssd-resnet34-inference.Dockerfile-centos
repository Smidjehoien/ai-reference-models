# Copyright (c) 2020-2021 Intel Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
#
# THIS IS A GENERATED DOCKERFILE.
#
# This file was assembled from multiple pieces, whose use is documented
# throughout. Please refer to the TensorFlow dockerfiles documentation
# for more information.

ARG TF_BASE_IMAGE=intel/intel-optimized-tensorflow
ARG TF_BASE_TAG=2.13-pip-base

FROM ${TF_BASE_IMAGE}:${TF_BASE_TAG}

ENV DEBIAN_FRONTEND=noninteractive

WORKDIR /workspace/tf-ssd-resnet34-inference

RUN yum update -y && \
    yum install -y git \
        cmake \
        unzip \
        ca-certificates \
        python3-tkinter && \
    yum clean all

COPY benchmarks benchmarks
COPY models models
COPY quickstart/common quickstart/common
COPY quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/multi_instance_online_inference_1200.sh quickstart/multi_instance_online_inference_1200.sh
COPY quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/multi_instance_batch_inference_1200.sh quickstart/multi_instance_batch_inference_1200.sh
COPY quickstart/object_detection/tensorflow/ssd-resnet34/inference/cpu/accuracy_1200.sh quickstart/accuracy_1200.sh

ARG TF_MODELS_BRANCH

ARG FETCH_PR

ARG CODE_DIR=/workspace/models

ENV TF_MODELS_DIR=${CODE_DIR}

RUN git clone https://github.com/tensorflow/models.git ${CODE_DIR} && \
    ( cd ${CODE_DIR} && \
    if [ ! -z "${FETCH_PR}" ]; then git fetch origin ${FETCH_PR}; fi && \
    git checkout ${TF_MODELS_BRANCH} )

# Note pycocotools has to be install after the other requirements

# Downloads protoc and runs it for object detection
RUN cd ${TF_MODELS_DIR}/research && \
    wget --quiet -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.3.0/protoc-3.3.0-linux-x86_64.zip && \
    unzip -o protobuf.zip && \
    rm protobuf.zip && \
    ./bin/protoc object_detection/protos/*.proto --python_out=.

# Note pycocotools has to be install after the other requirements
RUN python -m pip install Cython \
        contextlib2 \
        jupyter \
        lxml \
        matplotlib \
        numpy>=1.17.4 \
        'pillow>=9.3.0' \
        pycocotools

RUN yum update -y && \
    yum install -y \
       mesa-libGL \
       glib2-devel && \
    yum clean all

RUN python -m pip install opencv-python

ARG TF_BENCHMARKS_BRANCH

ARG TF_BENCHMARKS_DIR="/workspace/ssd-resnet-benchmarks"

ENV TF_BENCHMARKS_DIR=${TF_BENCHMARKS_DIR}

RUN yum update && \
    git clone --single-branch https://github.com/tensorflow/benchmarks.git ${TF_BENCHMARKS_DIR} && \
    ( cd ${TF_BENCHMARKS_DIR} && \
    git checkout ${TF_BENCHMARKS_BRANCH} )

COPY LICENSE license/LICENSE
COPY third_party license/third_party

RUN mkdir -p /workspace/tf-ssd-resnet34-inference/pretrained_model && \
    wget -qO /workspace/tf-ssd-resnet34-inference/pretrained_model/ssd_resnet34_fp32_1200x1200_pretrained_model.pb https://storage.googleapis.com/intel-optimized-tensorflow/models/2_10_0/ssd_resnet34_fp32_1200x1200_pretrained_model.pb && \
    wget -qO /workspace/tf-ssd-resnet34-inference/pretrained_model/ssd_resnet34_int8_1200x1200_pretrained_model.pb https://storage.googleapis.com/intel-optimized-tensorflow/models/2_10_0/ssd_resnet34_int8_1200x1200_pretrained_model.pb
