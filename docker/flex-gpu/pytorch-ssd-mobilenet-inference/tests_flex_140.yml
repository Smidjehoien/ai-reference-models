---
pytorch-flex-gpu-ssd-mobilenet-inference:
  image_name: intel/object-detection:pytorch-flex-gpu-ssd-mobilenet-inference
  tests:
  - test_name: SSD-MobileNet INT8 batch inference on Flex 140
    env_vars:
      PRECISION: int8
      SCRIPT: quickstart/flex_multi_card_batch_inference.sh
      BATCH_SIZE: 256
      NUM_ITERATIONS: 500
      DATASET_DIR: /pytorch/VOCDevkit/VOC2007
      OUTPUT_DIR: /output/flex-gpu-ssd-mobilenet-inference
      label: /workspace/pytorch-flex-series-ssd-mobilenet-inference/labels/voc-model-labels.txt
      DOCKER_ARGS: --cap-add=SYS_NICE --ipc=host --privileged --device=/dev/dri
    volumes:
      DATASET_DIR: /pytorch/VOCDevkit/VOC2007
      OUTPUT_DIR: /output/flex-gpu-ssd-mobilenet-inference
  - test_name: SSD-MobileNet INT8 online inference on Flex 140
    env_vars:
      PRECISION: int8
      SCRIPT: quickstart/flex_multi_card_online_inference.sh
      BATCH_SIZE: 1
      NUM_ITERATIONS: 5000
      DATASET_DIR: /pytorch/VOCDevkit/VOC2007
      OUTPUT_DIR: /output/flex-gpu-ssd-mobilenet-inference
      label: /workspace/pytorch-flex-series-ssd-mobilenet-inference/labels/voc-model-labels.txt
      DOCKER_ARGS: --cap-add=SYS_NICE --ipc=host --privileged --device=/dev/dri
    volumes:
      DATASET_DIR: /pytorch/VOCDevkit/VOC2007
      OUTPUT_DIR: /output/flex-gpu-ssd-mobilenet-inference
